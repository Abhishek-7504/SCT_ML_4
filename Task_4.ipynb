{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HAND RECOGNITON"
      ],
      "metadata": {
        "id": "4h7pTAf6t2y4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q52j44ksD5W",
        "outputId": "e2e89035-1a5b-4f0a-e070-545aa1db6d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "# Here we import everything we need for the project\n",
        "\n",
        "%matplotlib inline\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split # Helps with organizing data for training\n",
        "from sklearn.metrics import confusion_matrix # Helps present results as a confusion-matrix\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOADING DATA"
      ],
      "metadata": {
        "id": "96UvT5s3t_LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.google.com/url?q=https%3A%2F%2Fwww.kaggle.com%2Fgti-upm%2Fleapgestrecog%2Fversion%2F1"
      ],
      "metadata": {
        "id": "JbVIMSFDtL3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip images, ignore this cell if files are already in the workspace\n",
        "!unzip leapGestRecog.zip"
      ],
      "metadata": {
        "id": "nCevscX6sjeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to get all the paths for the images to later load them\n",
        "imagepaths = []\n",
        "\n",
        "# Go through all the files and subdirectories inside a folder and save path to images inside list\n",
        "for root, dirs, files in os.walk(\".\", topdown=False):\n",
        "  for name in files:\n",
        "    path = os.path.join(root, name)\n",
        "    if path.endswith(\"png\"): # We want only the images\n",
        "      imagepaths.append(path)\n",
        "\n",
        "print(len(imagepaths)) # If > 0, then a PNG image was loaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj6xEtQxsOE8",
        "outputId": "0817c8b4-6599-4058-879f-03bf53e68ace"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is used more for debugging and showing results later. It plots the image into the notebook\n",
        "\n",
        "def plot_image(path):\n",
        "  img = cv2.imread(path) # Reads the image into a numpy.array\n",
        "  img_cvt = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (RGB)\n",
        "  print(img_cvt.shape) # Prints the shape of the image just to check\n",
        "  plt.grid(False) # Without grid so we can see better\n",
        "  plt.imshow(img_cvt) # Shows the image\n",
        "  plt.xlabel(\"Width\")\n",
        "  plt.ylabel(\"Height\")\n",
        "  plt.title(\"Image \" + path)"
      ],
      "metadata": {
        "id": "ZWNyzEYatQiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_image(imagepaths[0]) #We plot the first image from our imagepaths array"
      ],
      "metadata": {
        "id": "nGdYQF92tUJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [] # Image data\n",
        "y = [] # Labels\n",
        "\n",
        "# Loops through imagepaths to load images and labels into arrays\n",
        "for path in imagepaths:\n",
        "  img = cv2.imread(path) # Reads image and returns np.array\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (GRAY)\n",
        "  img = cv2.resize(img, (320, 120)) # Reduce image size so training can be faster\n",
        "  X.append(img)\n",
        "\n",
        "  # Processing label in image path\n",
        "  category = path.split(\"/\")[3]\n",
        "  label = int(category.split(\"_\")[0][1]) # We need to convert 10_down to 00_down, or else it crashes\n",
        "  y.append(label)\n",
        "\n",
        "# Turn X and y into np.array to speed up train_test_split\n",
        "X = np.array(X, dtype=\"uint8\")\n",
        "X = X.reshape(len(imagepaths), 120, 320, 1) # Needed to reshape so CNN knows it's different images\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Images loaded: \", len(X))\n",
        "print(\"Labels loaded: \", len(y))\n",
        "\n",
        "print(y[0], imagepaths[0]) # Debugging"
      ],
      "metadata": {
        "id": "xjiXw43dtWfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = 0.3 # Percentage of images that we want to use for testing. The rest is used for training.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, random_state=42)"
      ],
      "metadata": {
        "id": "jIhA2cyYtYRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  CREATING THE MODEL"
      ],
      "metadata": {
        "id": "oZBCDxJTuEfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the exact same model, including weights and optimizer.\n",
        "# model = keras.models.load_model('handrecognition_model.h5')\n",
        "# model.summary()\n",
        "\n",
        "# To use the pre-trained model, just load it and skip to the next session."
      ],
      "metadata": {
        "id": "eDBY2UAKtanz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import of keras model and hidden layers for our convolutional network\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "J2dp_n3Ltb4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.google.com/url?q=https%3A%2F%2Fwww.tensorflow.org%2Ftutorials%2Festimators%2Fcnn"
      ],
      "metadata": {
        "id": "5ye8S3GUtecR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construction of model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(120, 320, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "WeFgu-h7tfVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configures the model for training\n",
        "model.compile(optimizer='adam', # Optimization routine, which tells the computer how to adjust the parameter values to minimize the loss function.\n",
        "              loss='sparse_categorical_crossentropy', # Loss function, which tells us how bad our predictions are.\n",
        "              metrics=['accuracy']) # List of metrics to be evaluated by the model during training and testing."
      ],
      "metadata": {
        "id": "SlUNzVmvtiL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains the model for a given number of epochs (iterations on a dataset) and validates it.\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=2, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "3QDSw_aitjab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save entire model to a HDF5 file\n",
        "model.save('handrecognition_model.h5')"
      ],
      "metadata": {
        "id": "RDV6NqlBtkxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING MODEL"
      ],
      "metadata": {
        "id": "ebqJ-30cuKbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test accuracy: {:2.2f}%'.format(test_acc*100))"
      ],
      "metadata": {
        "id": "P-_6pIYhtmND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test) # Make predictions towards the test set"
      ],
      "metadata": {
        "id": "G8kRdv1Ptngi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[0]), y_test[0] # If same, got it right"
      ],
      "metadata": {
        "id": "_xUUFNKstoew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot images and labels for validation purposes\n",
        "def validate_9_images(predictions_array, true_label_array, img_array):\n",
        "  # Array for pretty printing and then figure size\n",
        "  class_names = [\"down\", \"palm\", \"l\", \"fist\", \"fist_moved\", \"thumb\", \"index\", \"ok\", \"palm_moved\", \"c\"]\n",
        "  plt.figure(figsize=(15,5))\n",
        "\n",
        "  for i in range(1, 10):\n",
        "    # Just assigning variables\n",
        "    prediction = predictions_array[i]\n",
        "    true_label = true_label_array[i]\n",
        "    img = img_array[i]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Plot in a good way\n",
        "    plt.subplot(3,3,i)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(prediction) # Get index of the predicted label from prediction\n",
        "\n",
        "    # Change color of title based on good prediction or not\n",
        "    if predicted_label == true_label:\n",
        "      color = 'blue'\n",
        "    else:\n",
        "      color = 'red'\n",
        "\n",
        "    plt.xlabel(\"Predicted: {} {:2.0f}% (True: {})\".format(class_names[predicted_label],\n",
        "                                  100*np.max(prediction),\n",
        "                                  class_names[true_label]),\n",
        "                                  color=color)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "WUg0hg8ztp-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_9_images(predictions, y_test, X_test)"
      ],
      "metadata": {
        "id": "ERBmZouktriO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(predictions, axis=1) # Transform predictions into 1-D array with label number"
      ],
      "metadata": {
        "id": "ARMwVynXtsyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# H = Horizontal\n",
        "# V = Vertical\n",
        "\n",
        "pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
        "             columns=[\"Predicted Thumb Down\", \"Predicted Palm (H)\", \"Predicted L\", \"Predicted Fist (H)\", \"Predicted Fist (V)\", \"Predicted Thumbs up\", \"Predicted Index\", \"Predicted OK\", \"Predicted Palm (V)\", \"Predicted C\"],\n",
        "             index=[\"Actual Thumb Down\", \"Actual Palm (H)\", \"Actual L\", \"Actual Fist (H)\", \"Actual Fist (V)\", \"Actual Thumbs up\", \"Actual Index\", \"Actual OK\", \"Actual Palm (V)\", \"Actual C\"])"
      ],
      "metadata": {
        "id": "gE6we3xOtuLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}